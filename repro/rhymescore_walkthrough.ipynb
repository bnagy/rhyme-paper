{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the rhyme scoring code\n",
    "\n",
    "This notebook is mainly to provide more insight into the rhyme scoring algorithm. In the end, the scoring code has quite a few moving parts, and it wasn't practical to try and explain it in the paper, but the reviwers were keen to see the full details. Note that this code won't run standalone, I've just pulled out the core of the scoring code to explain how it works.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vowel similarity\n",
    "\n",
    "First let's look at the implementation of the vowel similarity. This is simply based on the closeness of the vowels of Latin according to a 'normal' linguistic formant frequency chart. The vowels of Latin are below. Note that I do not differentiate between long and short vowels, which renders a considerable amount of controversy moot. Allen in _Vox Latina_ posits a system in which some long vowels are positioned differently to the short ones. Weiss and Calabrese more or less suggest a 5-vowel system (not including the Greek y in their analysis) and there is a good overview of the discussion on reddit (not exactly a scholarly source, but it's an efficient description by someone who clearly knows what they're talking about) [here](https://www.reddit.com/r/latin/comments/95yxez/vowel_pronunciation_beyond_allens_vox_latina/)\n",
    "\n",
    "![Rhyme Vowel Similarity](rhyme_vowelsim.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:21:42.033671Z",
     "iopub.status.busy": "2021-08-12T02:21:42.033119Z",
     "iopub.status.idle": "2021-08-12T02:21:42.050376Z",
     "shell.execute_reply": "2021-08-12T02:21:42.044682Z",
     "shell.execute_reply.started": "2021-08-12T02:21:42.033459Z"
    }
   },
   "outputs": [],
   "source": [
    "# 10/11 bumped i-e slightly and o-a slightly based on\n",
    "# Hirjee & Brown\n",
    "NUCLEUS_SCORES = {\n",
    "    \"i\": {\"i\": 1, \"e\": 0.75, \"a\": 0.5, \"o\": 0.42, \"u\": 0.4, \"ü\": 0.5},\n",
    "    \"e\": {\"i\": 0.75, \"e\": 1, \"a\": 0.6, \"o\": 0.5, \"u\": 0.42, \"ü\": 0.5},\n",
    "    \"a\": {\"i\": 0.5, \"e\": 0.6, \"a\": 1, \"o\": 0.6, \"u\": 0.42, \"ü\": 0.4},\n",
    "    \"o\": {\"i\": 0.42, \"e\": 0.5, \"a\": 0.6, \"o\": 1, \"u\": 0.75, \"ü\": 0.35},\n",
    "    \"u\": {\"i\": 0.4, \"e\": 0.42, \"a\": 0.42, \"o\": 0.75, \"u\": 1, \"ü\": 0.6},\n",
    "    \"ü\": {\"i\": 0.5, \"e\": 0.5, \"a\": 0.4, \"o\": 0.35, \"u\": 0.6, \"ü\": 1},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consonant similarity\n",
    "\n",
    "In standard rhyme, the syllable onsets are ignored, but the codas are important (ie 'bat' and 'cat' are perfect rhymes but 'kit' and 'kin' are not). Wherever consonants are important, we need to consider the quality of imperfect rhymes, so 'cut' and 'cup' are better than 'cut' and 'cuff'. In this implementation I only create one level of similarity, so two consonants are either identical, similar or dissimilar. The code below determines that similarity based on phonological features, but it is slightly complicated by the fact that, to my ear, some pairs that sound similar in an onset do not match as well in a coda. Finally, for the final syllable (always unstressed in Latin) I do consider the onset so that things like /ra.bit/ and /ra.bid/ can be upgraded due to the matching 'b'.\n",
    "\n",
    "Essentially similar consonants just give a bonus to the rhyme score, but the exact details are a bit fiddly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:21:42.053247Z",
     "iopub.status.busy": "2021-08-12T02:21:42.052684Z",
     "iopub.status.idle": "2021-08-12T02:21:42.089899Z",
     "shell.execute_reply": "2021-08-12T02:21:42.086512Z",
     "shell.execute_reply.started": "2021-08-12T02:21:42.053025Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a bunch of feature classes as sets. These are fairly standard phonological classes.\n",
    "\n",
    "# fricatives\n",
    "FRIC = {\"s\", \"f\", \"z\", \"h\"}\n",
    "\n",
    "# stops, voiced / unvoiced\n",
    "UNV_STOP = {\"k\", \"t\", \"p\"}\n",
    "V_STOP = {\"g\", \"d\", \"b\"}\n",
    "STOP = UNV_STOP | V_STOP\n",
    "\n",
    "ALVEOLAR = {\"t\", \"d\", \"s\", \"z\"}\n",
    "VELAR = {\"g\", \"k\"}\n",
    "# bilabial\n",
    "BILAB = {\"p\", \"b\", \"w\"}\n",
    "# sonorant\n",
    "SON = {\"n\", \"m\", \"l\", \"r\"}\n",
    "# nasal\n",
    "NAS = {\"n\", \"m\"}\n",
    "# approximants\n",
    "APPROX = {\"j\", \"w\", \"l\", \"r\"}\n",
    "CONT = SON | NAS | FRIC | {\"\"}\n",
    "\n",
    "CONS_CLOSE = {\n",
    "    \"\": FRIC | UNV_STOP | NAS | {\"\"},\n",
    "    \"t\": ALVEOLAR | STOP,\n",
    "    \"d\": STOP,\n",
    "    \"s\": FRIC | (UNV_STOP - BILAB),\n",
    "    \"f\": FRIC,\n",
    "    \"k\": STOP - BILAB,\n",
    "    \"h\": STOP,  # only occurs as kh and th which are both stops\n",
    "    \"g\": STOP - BILAB,\n",
    "    \"r\": SON,\n",
    "    \"n\": SON,\n",
    "    \"m\": CONT,  # m isn't really there, it nasalises the vowel\n",
    "    \"l\": SON,\n",
    "    \"b\": (V_STOP | BILAB) - VELAR,  # b--g seems too far away\n",
    "    \"p\": STOP - VELAR,\n",
    "    \"x\": UNV_STOP | FRIC,\n",
    "    \"w\": BILAB,\n",
    "    \"j\": APPROX,\n",
    "}\n",
    "\n",
    "CLOSE_STRESSED_CODA = {\n",
    "    \"\": FRIC | UNV_STOP,\n",
    "    \"b\": STOP,\n",
    "    \"k\": STOP,\n",
    "    \"d\": STOP,\n",
    "    \"f\": FRIC,\n",
    "    \"g\": STOP,\n",
    "    \"h\": STOP,  # only occurs in coda as kh and th which are both stops\n",
    "    \"j\": APPROX,\n",
    "    \"l\": SON,\n",
    "    \"m\": SON,\n",
    "    \"n\": SON,\n",
    "    \"p\": STOP,\n",
    "    \"r\": SON,\n",
    "    \"s\": FRIC | (UNV_STOP - BILAB),\n",
    "    \"t\": ALVEOLAR | (UNV_STOP - BILAB),\n",
    "    \"w\": {\"w\"},  # should not appear in coda\n",
    "    \"x\": {\"x\"},\n",
    "}\n",
    "\n",
    "CLOSE_FINAL_ONSET = {\n",
    "    \"b\": STOP,\n",
    "    \"k\": VELAR,\n",
    "    \"d\": {\"d\", \"t\"},\n",
    "    \"f\": FRIC,\n",
    "    \"g\": VELAR,\n",
    "    \"h\": FRIC,\n",
    "    \"j\": APPROX,\n",
    "    \"l\": {\"r\"},\n",
    "    \"m\": NAS,\n",
    "    \"n\": NAS,\n",
    "    \"p\": STOP - VELAR,\n",
    "    \"r\": {\"l\"},\n",
    "    \"s\": FRIC | {\"t\"},\n",
    "    \"t\": FRIC | {\"k\", \"d\", \"r\"},\n",
    "    \"w\": APPROX,\n",
    "    \"x\": {\"x\"},\n",
    "    \"\": {\"\"},\n",
    "}\n",
    "\n",
    "CLOSE_FINAL_CODA = {\n",
    "    \"b\": V_STOP,\n",
    "    \"k\": UNV_STOP,\n",
    "    \"d\": V_STOP,\n",
    "    \"f\": FRIC,\n",
    "    \"g\": VELAR,\n",
    "    \"h\": UNV_STOP,\n",
    "    \"j\": {\"j\"},  # shouldn't happen\n",
    "    \"l\": {\"r\"},\n",
    "    \"m\": NAS | {\" \"},\n",
    "    \"n\": NAS,\n",
    "    \"p\": UNV_STOP,\n",
    "    \"r\": {\"l\"},\n",
    "    \"s\": FRIC | {\"t\"},\n",
    "    \"t\": {\"s\", \"p\", \"k\", \"d\"},\n",
    "    \"w\": {\"w\"},  # shouldn't happen\n",
    "    \"x\": {\"x\"},\n",
    "    \"\": {\"\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nuclei\n",
    "\n",
    "Score the a pair of syllables according to the nucleus. Diphthongs are allowed, and we score them according to the final position (ie 'ae' ends at 'e')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:21:42.093086Z",
     "iopub.status.busy": "2021-08-12T02:21:42.092517Z",
     "iopub.status.idle": "2021-08-12T02:21:42.115866Z",
     "shell.execute_reply": "2021-08-12T02:21:42.113322Z",
     "shell.execute_reply.started": "2021-08-12T02:21:42.092869Z"
    }
   },
   "outputs": [],
   "source": [
    "def _score_nucleus(s1, s2):\n",
    "    if s1.nucleus == \"\" or s2.nucleus == \"\":\n",
    "        return 0\n",
    "    try:\n",
    "        # Basic score for the final vowel\n",
    "        nuc1 = s1.nucleus.translate(DEMACRON).lower()\n",
    "        nuc2 = s2.nucleus.translate(DEMACRON).lower()\n",
    "        v1 = s1.main_vowel\n",
    "        v2 = s2.main_vowel\n",
    "        score = NUCLEUS_SCORES[v1][v2]\n",
    "        # print(\"Basic score for %s %s: %.2f\" % (s1,s2,score))\n",
    "\n",
    "        # One's a dipthong and one isn't, apply a penalty\n",
    "        if len(nuc1) != len(nuc2):\n",
    "            score *= 0.7\n",
    "        elif (nuc1 != nuc2) and (v1 == v2):\n",
    "            # two dipthongs but only last vowel equal\n",
    "            score *= 0.7\n",
    "        elif nuc1 == nuc2:\n",
    "            # mismatched nasalisation:\n",
    "            # if 1 (but not 0 or 2) of the nuclei is nasalised apply a small penalty\n",
    "            if len([x for x in [s1.nucleus, s2.nucleus] if COMBINING_TILDE in x]) == 1:\n",
    "                score *= 0.9\n",
    "        else:\n",
    "            # mismatched dipthongs or mismatched single letters\n",
    "            score = score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(s1)\n",
    "        print(s2)\n",
    "        raise e\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllable rhymes\n",
    "\n",
    "Now two methods for calulating the rhyme for two syllables. The algorithm is slightly different for the stressed syllable as compared to the final syllable. Some words also have a mismatched number of syllables involved in the rhyme, which receives a penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:21:42.118635Z",
     "iopub.status.busy": "2021-08-12T02:21:42.118287Z",
     "iopub.status.idle": "2021-08-12T02:21:42.184862Z",
     "shell.execute_reply": "2021-08-12T02:21:42.183813Z",
     "shell.execute_reply.started": "2021-08-12T02:21:42.118578Z"
    }
   },
   "outputs": [],
   "source": [
    "def _stressed_syl_rhyme(s1, s2):\n",
    "    # onset doesn't matter, less fussy about 'r' in coda\n",
    "    score = _score_nucleus(s1, s2)\n",
    "\n",
    "    last1 = s1.coda[-1:].lower()\n",
    "    last2 = s2.coda[-1:].lower()\n",
    "\n",
    "    try:\n",
    "\n",
    "        # perfect match receives a bonus\n",
    "        if s1.coda == s2.coda:\n",
    "            if s1.coda:\n",
    "                score *= 1.2\n",
    "            else:\n",
    "                score *= 1\n",
    "\n",
    "        elif len(s1.coda) + len(s2.coda) > 2:\n",
    "            # at least one consonant cluster\n",
    "            if \"s\" in s1.coda.lower() and \"s\" in s2.coda.lower():\n",
    "                # ast as are close\n",
    "                score *= 0.95\n",
    "            elif (\n",
    "                last2 in CLOSE_STRESSED_CODA[last1]\n",
    "                or last1 in CLOSE_STRESSED_CODA[last2]\n",
    "            ):\n",
    "                # otherwise go by the final consonant - pakt part are close (?review?)\n",
    "                score *= 0.9\n",
    "            else:\n",
    "                score *= 0.8\n",
    "\n",
    "        elif last2 in CLOSE_STRESSED_CODA[last1] or last1 in CLOSE_STRESSED_CODA[last2]:\n",
    "            score *= 0.95\n",
    "\n",
    "        else:\n",
    "            score *= 0.8\n",
    "\n",
    "    except KeyError:\n",
    "        score *= 0.8\n",
    "\n",
    "    if score > 1:\n",
    "        score = 1\n",
    "    return score\n",
    "\n",
    "\n",
    "def _final_syl_rhyme(s1, s2):\n",
    "\n",
    "    # TODO move the magic score multipliers into a config dict\n",
    "    \n",
    "    # in the final syllable we apply a bonus\n",
    "    # for matching onsets, stricter about codas\n",
    "    score = _score_nucleus(s1, s2)\n",
    "\n",
    "    first1 = s1.onset[0:1].lower()\n",
    "    first2 = s2.onset[0:1].lower()\n",
    "\n",
    "    try:\n",
    "        if s1.onset == s2.onset:\n",
    "            score *= 1.1\n",
    "\n",
    "        elif len(s1.onset) + len(s2.onset) > 2:\n",
    "            # at least one cluster\n",
    "            if (\n",
    "                first2 in CLOSE_FINAL_ONSET[first1]\n",
    "                or first1 in CLOSE_FINAL_ONSET[first2]\n",
    "            ):\n",
    "                # otherwise go by the initial consonant - tra and ta are close (?review?)\n",
    "                score *= 0.95\n",
    "            else:\n",
    "                score *= 0.85\n",
    "\n",
    "        elif first2 in CLOSE_FINAL_ONSET[first1] or first1 in CLOSE_FINAL_ONSET[first2]:\n",
    "            score *= 1\n",
    "\n",
    "        else:\n",
    "            score *= 0.85\n",
    "    except KeyError:\n",
    "        score *= 0.85\n",
    "\n",
    "    last1 = s1.coda[-1:].lower()\n",
    "    last2 = s2.coda[-1:].lower()\n",
    "\n",
    "    try:\n",
    "\n",
    "        # perfect match is good\n",
    "        if s1.coda == s2.coda:\n",
    "            if s1.coda:\n",
    "                score *= 1.2\n",
    "            else:\n",
    "                score *= 1.1\n",
    "\n",
    "        elif len(s1.coda) + len(s2.coda) > 2:\n",
    "            # at least one cluster\n",
    "            if \"s\" in s1.coda.lower() and \"s\" in s2.coda.lower():\n",
    "                # ast as are close\n",
    "                score *= 0.95\n",
    "            elif (\n",
    "                last2 in CLOSE_STRESSED_CODA[last1]\n",
    "                or last1 in CLOSE_STRESSED_CODA[last2]\n",
    "            ):\n",
    "                # otherwise go by the final consonant - pakt part are close (?review?)\n",
    "                score *= 0.9\n",
    "            else:\n",
    "                score *= 0.8\n",
    "\n",
    "        elif last2 in CLOSE_STRESSED_CODA[last1] or last1 in CLOSE_STRESSED_CODA[last2]:\n",
    "            score *= 0.95\n",
    "\n",
    "        else:\n",
    "            score *= 0.8\n",
    "\n",
    "    except KeyError:\n",
    "        score *= 0.8\n",
    "\n",
    "    if score > 1:\n",
    "        score = 1\n",
    "    return score\n",
    "\n",
    "def word_rhyme(w1, w2) -> (float):\n",
    "\n",
    "    \"\"\"Score the rhyme of two Words. Safe to call if one or\n",
    "    both of the words are None (will return 0).\n",
    "\n",
    "    Args:\n",
    "        w1, w2 (rhyme_classes.Word): words to score\n",
    "\n",
    "    Returns:\n",
    "        (float): The score.\n",
    "    \"\"\"\n",
    "\n",
    "    # This is so the user can call this with something\n",
    "    # like l[-1] vs l.midword, where midword might not exist\n",
    "    if not w1 or not w2:\n",
    "        return 0\n",
    "\n",
    "    # syls _might_ be empty, if the word is 'est' and it got eaten\n",
    "    # by the previous word (prodelision)\n",
    "    if len(w1.syls) == 0 or len(w2.syls) == 0:\n",
    "        return 0\n",
    "\n",
    "    if len(w1.syls) == 1 and len(w2.syls) == 1:\n",
    "        s = _final_syl_rhyme(w1.syls[0], w2.syls[0])\n",
    "        return s * 2\n",
    "\n",
    "    # calculate the rhyme score on the stressed syllable\n",
    "    stress_score = _stressed_syl_rhyme(w1.stressed_syllable, w2.stressed_syllable)\n",
    "    score = stress_score\n",
    "\n",
    "    # Now the rhyme on the remainder. In Latin, in theory,\n",
    "    # the final syllable is never stressed, so there should be\n",
    "    # at least one extra, but there _are_ exceptions.\n",
    "\n",
    "    # For uneven lengths, if we have Xx vs Yyy then compare\n",
    "    # the two final syllables, slurring over like\n",
    "    # UN.də.ground // COM.pound\n",
    "    coda_score = 0\n",
    "\n",
    "    if len(w1.post_stress) > 0 and len(w2.post_stress) > 0:\n",
    "        # single syllable words have their score doubled during\n",
    "        # final_syl_rhyme\n",
    "        coda_score = _final_syl_rhyme(w1.syls[-1], w2.syls[-1])\n",
    "\n",
    "        # bump up really good final syllable matches. This biases the approach\n",
    "        # somewhat since the final syllable is unstressed, but I have a pretty\n",
    "        # strong intuition that this sort of final-syllable assonance/slant-rhyme\n",
    "        # was important. On this see also Norberg (1968) 'Manuel pratique de Latin medieval'.\n",
    "        # Norberg traces the development of medeval rhyme to final-syllable assonances\n",
    "        # (some quite weak) in Sedulius in C4 CE, believing (as was common)\n",
    "        # that classical rhyme was only accidental.\n",
    "        if coda_score >= 0.75:\n",
    "            coda_score *= 1.3\n",
    "\n",
    "        # apply a small penalty for interstitial syllables between\n",
    "        # stressed and final if there's a length mismatch\n",
    "        # TODO: consider lightening this penalty. It was probably\n",
    "        # routine to swallow these interstitials in 'normal' speech\n",
    "        # and so perhaps too in poetry.\n",
    "        # \"Sed Augustus quoque in epistulis ad C. Caesarem\n",
    "        # scriptis emendat quod is 'calidum' dicere quam 'caldum'\n",
    "        # malit, non quia id non sit Latinum, sed quia sit odiosum\"\n",
    "        # (Quint. 1.6.19)\n",
    "        if len(w1.post_stress) + len(w2.post_stress) == 3:\n",
    "            # a 1 and a 2. This will be 99% of the cases. If it's\n",
    "            # not this then something weird is happening and the\n",
    "            # rest of the logic here might break.\n",
    "            longer = max(w1.post_stress, w2.post_stress, key=len)\n",
    "            # mid-low vowels (e,a,o) get pronounced as a schwa in the interstitial syllable\n",
    "            # but high ones (i,u,ü) sound more obtrusive to me.\n",
    "            if (\n",
    "                len(longer[1].nucleus.translate(DEMACRON).lower()) > 1\n",
    "                or longer[1].main_vowel in \"iuü\"\n",
    "            ):\n",
    "                coda_score *= 0.73\n",
    "            else:\n",
    "                coda_score *= 0.83\n",
    "\n",
    "        score += coda_score\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring some words\n",
    "\n",
    "Here I'll just run through the kind of code used to produce Table 1 (the list of example rhyme scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:21:42.186872Z",
     "iopub.status.busy": "2021-08-12T02:21:42.186040Z",
     "iopub.status.idle": "2021-08-12T02:21:43.596905Z",
     "shell.execute_reply": "2021-08-12T02:21:43.596159Z",
     "shell.execute_reply.started": "2021-08-12T02:21:42.186754Z"
    }
   },
   "outputs": [],
   "source": [
    "from mqdq import rhyme, babble\n",
    "\n",
    "import random\n",
    "import string\n",
    "import scipy as sp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:23:53.960497Z",
     "iopub.status.busy": "2021-08-12T02:23:53.960035Z",
     "iopub.status.idle": "2021-08-12T02:24:11.333604Z",
     "shell.execute_reply": "2021-08-12T02:24:11.332704Z",
     "shell.execute_reply.started": "2021-08-12T02:23:53.960447Z"
    }
   },
   "outputs": [],
   "source": [
    "met_single_bab = babble.Babbler.from_file('mqdq/OV-meta.xml', name='Metamorphoses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:24:18.347108Z",
     "iopub.status.busy": "2021-08-12T02:24:18.346743Z",
     "iopub.status.idle": "2021-08-12T02:24:31.305994Z",
     "shell.execute_reply": "2021-08-12T02:24:31.305177Z",
     "shell.execute_reply.started": "2021-08-12T02:24:18.346967Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is now how I would normally syllabify, but if we want to examine\n",
    "# individual word rhymes we need to take them before applying elision,\n",
    "# prodelision etc. The 'normal' system calculates rhyme for the line\n",
    "# as pronounced, ie if 'tua est' is at the end of a line the 'final' word\n",
    "# is tuast, NOT est.\n",
    "\n",
    "words = []\n",
    "for l in met_single_bab.raw_source:\n",
    "    a = [rhyme._phonetify(rhyme._syllabify_word(x)) for x in l('word')]\n",
    "    words.extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:24:31.307567Z",
     "iopub.status.busy": "2021-08-12T02:24:31.307088Z",
     "iopub.status.idle": "2021-08-12T02:24:31.348801Z",
     "shell.execute_reply": "2021-08-12T02:24:31.348065Z",
     "shell.execute_reply.started": "2021-08-12T02:24:31.307354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Collect 25 random pairs of words whose rhyme score is \n",
    "# above 1.75 (the global threshhold used in all the experiments)\n",
    "\n",
    "pairs = []\n",
    "while len(pairs) < 25:\n",
    "    w1, w2 = random.sample(words, 2)\n",
    "    a = w1.mqdq.text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    b = w2.mqdq.text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    if a==b:\n",
    "        continue\n",
    "    score, ss, cs = rhyme._word_rhyme_debug(w1,w2)\n",
    "    if 1.75 <= score:\n",
    "        pairs.append((w1,w2,(score,ss,cs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:24:34.678200Z",
     "iopub.status.busy": "2021-08-12T02:24:34.677713Z",
     "iopub.status.idle": "2021-08-12T02:24:34.692300Z",
     "shell.execute_reply": "2021-08-12T02:24:34.691452Z",
     "shell.execute_reply.started": "2021-08-12T02:24:34.678117Z"
    }
   },
   "outputs": [],
   "source": [
    "def table(pairs):\n",
    "    res = []\n",
    "    for p in pairs:\n",
    "        score = p[2][0]\n",
    "        syls1 = ('.'.join(p[0].syls)).lower()\n",
    "        syls2 = ('.'.join(p[1].syls)).lower()\n",
    "        w1 = p[0].mqdq.text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        w2 = p[1].mqdq.text.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        row = {\n",
    "            'orth1': w1,\n",
    "            'orth2': w2,\n",
    "            'phon1': syls1,\n",
    "            'phon2': syls2,\n",
    "            'score': score,\n",
    "            'stress': p[2][1],\n",
    "            'final': p[2][2],\n",
    "        }\n",
    "        res.append(row)\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-12T02:24:35.894347Z",
     "iopub.status.busy": "2021-08-12T02:24:35.893966Z",
     "iopub.status.idle": "2021-08-12T02:24:35.928419Z",
     "shell.execute_reply": "2021-08-12T02:24:35.926864Z",
     "shell.execute_reply.started": "2021-08-12T02:24:35.894198Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orth1</th>\n",
       "      <th>orth2</th>\n",
       "      <th>phon1</th>\n",
       "      <th>phon2</th>\n",
       "      <th>score</th>\n",
       "      <th>stress</th>\n",
       "      <th>final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sola</td>\n",
       "      <td>auras</td>\n",
       "      <td>`sō.la</td>\n",
       "      <td>`au.ras</td>\n",
       "      <td>1.760000</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>1.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dapes</td>\n",
       "      <td>lyramque</td>\n",
       "      <td>`da.pes</td>\n",
       "      <td>lü.`ram.kwe</td>\n",
       "      <td>1.769750</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>1.049750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sequentes</td>\n",
       "      <td>phrygiisque</td>\n",
       "      <td>se.`kwen.tes</td>\n",
       "      <td>prü.gi.`īs.kwe</td>\n",
       "      <td>1.773250</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.173250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pueri</td>\n",
       "      <td>corpore</td>\n",
       "      <td>`pu.e.rī</td>\n",
       "      <td>`kor.po.re</td>\n",
       "      <td>1.779750</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.179750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>erit</td>\n",
       "      <td>foret</td>\n",
       "      <td>`e.rit</td>\n",
       "      <td>`fo.ret</td>\n",
       "      <td>1.787000</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>1.287000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>debita</td>\n",
       "      <td>persequar</td>\n",
       "      <td>`dē.bi.ta</td>\n",
       "      <td>`per.se.kwar</td>\n",
       "      <td>1.788000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>flere</td>\n",
       "      <td>frustraque</td>\n",
       "      <td>`fle.re</td>\n",
       "      <td>frus.`tra.kwe</td>\n",
       "      <td>1.815500</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>aquosis</td>\n",
       "      <td>aonides</td>\n",
       "      <td>a.`kwo.sis</td>\n",
       "      <td>ā.`o.ni.des</td>\n",
       "      <td>1.825435</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.825435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agitat</td>\n",
       "      <td>robora</td>\n",
       "      <td>`a.gi.tat</td>\n",
       "      <td>`rō.bo.ra</td>\n",
       "      <td>1.835000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>corrigit</td>\n",
       "      <td>potui</td>\n",
       "      <td>`kor.ri.git</td>\n",
       "      <td>`po.tu.ī</td>\n",
       "      <td>1.849750</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.049750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bellica</td>\n",
       "      <td>texerat</td>\n",
       "      <td>`bel.li.ka</td>\n",
       "      <td>`tek.se.rat</td>\n",
       "      <td>1.849750</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.049750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>furentibus</td>\n",
       "      <td>caestibus</td>\n",
       "      <td>fu.`ren.ti.bus</td>\n",
       "      <td>`kaes.ti.bus</td>\n",
       "      <td>1.860000</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>petis</td>\n",
       "      <td>cremabis</td>\n",
       "      <td>`pe.tis</td>\n",
       "      <td>kre.`mā.bis</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>perhorruit</td>\n",
       "      <td>intumuit</td>\n",
       "      <td>pe.`ror.ru.it</td>\n",
       "      <td>īn.`tu.mu.īt</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>fronde</td>\n",
       "      <td>fletumque</td>\n",
       "      <td>`fron.de</td>\n",
       "      <td>fle.`tum.kwe</td>\n",
       "      <td>1.928000</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>1.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acuta</td>\n",
       "      <td>auras</td>\n",
       "      <td>a.`kū.ta</td>\n",
       "      <td>`au.ras</td>\n",
       "      <td>1.935000</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>1.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>inde</td>\n",
       "      <td>ipse</td>\n",
       "      <td>`īn.de</td>\n",
       "      <td>`īp.se</td>\n",
       "      <td>1.935500</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>1.215500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>deus</td>\n",
       "      <td>venulus</td>\n",
       "      <td>`de.us</td>\n",
       "      <td>`we.nu.lus</td>\n",
       "      <td>1.949000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.949000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>deerit</td>\n",
       "      <td>conspexi</td>\n",
       "      <td>`dē.rit</td>\n",
       "      <td>kons.`pek.sī</td>\n",
       "      <td>1.999750</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>1.049750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>essem</td>\n",
       "      <td>diem</td>\n",
       "      <td>`ēs.sẽm</td>\n",
       "      <td>`di.ẽm</td>\n",
       "      <td>2.012500</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sensit</td>\n",
       "      <td>petit</td>\n",
       "      <td>`sen.sit</td>\n",
       "      <td>`pe.tit</td>\n",
       "      <td>2.020000</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>senior</td>\n",
       "      <td>experiar</td>\n",
       "      <td>`se.ni.ōr</td>\n",
       "      <td>eks.`pe.ri.ār</td>\n",
       "      <td>2.029600</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ubi</td>\n",
       "      <td>figuris</td>\n",
       "      <td>`u.bi</td>\n",
       "      <td>fi.`gū.ris</td>\n",
       "      <td>2.049750</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.049750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>euerberat</td>\n",
       "      <td>euolat</td>\n",
       "      <td>ē.`wer.be.rat</td>\n",
       "      <td>`ē.wo.lat</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>erit</td>\n",
       "      <td>moueri</td>\n",
       "      <td>`e.rit</td>\n",
       "      <td>mo.`wē.ri</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         orth1        orth2           phon1            phon2     score  \\\n",
       "4         sola        auras         `sō.la          `au.ras  1.760000   \n",
       "10       dapes     lyramque         `da.pes      lü.`ram.kwe  1.769750   \n",
       "15   sequentes  phrygiisque    se.`kwen.tes  prü.gi.`īs.kwe  1.773250   \n",
       "14       pueri      corpore       `pu.e.rī       `kor.po.re  1.779750   \n",
       "13        erit        foret          `e.rit          `fo.ret  1.787000   \n",
       "24      debita    persequar      `dē.bi.ta     `per.se.kwar  1.788000   \n",
       "8        flere   frustraque         `fle.re    frus.`tra.kwe  1.815500   \n",
       "21     aquosis      aonides      a.`kwo.sis     ā.`o.ni.des  1.825435   \n",
       "1       agitat       robora       `a.gi.tat       `rō.bo.ra  1.835000   \n",
       "0     corrigit        potui     `kor.ri.git        `po.tu.ī  1.849750   \n",
       "5      bellica      texerat      `bel.li.ka      `tek.se.rat  1.849750   \n",
       "19  furentibus    caestibus  fu.`ren.ti.bus     `kaes.ti.bus  1.860000   \n",
       "17       petis     cremabis         `pe.tis     kre.`mā.bis  1.900000   \n",
       "6   perhorruit     intumuit   pe.`ror.ru.it   īn.`tu.mu.īt  1.900000   \n",
       "22      fronde    fletumque        `fron.de     fle.`tum.kwe  1.928000   \n",
       "2        acuta        auras       a.`kū.ta          `au.ras  1.935000   \n",
       "11        inde         ipse         `īn.de          `īp.se  1.935500   \n",
       "7         deus      venulus          `de.us       `we.nu.lus  1.949000   \n",
       "16      deerit     conspexi        `dē.rit    kons.`pek.sī  1.999750   \n",
       "23       essem         diem       `ēs.sẽm          `di.ẽm  2.012500   \n",
       "3       sensit        petit        `sen.sit          `pe.tit  2.020000   \n",
       "9       senior     experiar      `se.ni.ōr   eks.`pe.ri.ār  2.029600   \n",
       "12         ubi      figuris           `u.bi      fi.`gū.ris  2.049750   \n",
       "20   euerberat       euolat  ē.`wer.be.rat       `ē.wo.lat  2.100000   \n",
       "18        erit       moueri          `e.rit       mo.`wē.ri  2.300000   \n",
       "\n",
       "    stress     final  \n",
       "4   0.5250  1.235000  \n",
       "10  0.7200  1.049750  \n",
       "15  0.6000  1.173250  \n",
       "14  0.6000  1.179750  \n",
       "13  0.5000  1.287000  \n",
       "24  0.8000  0.988000  \n",
       "8   0.6000  1.215500  \n",
       "21  1.0000  0.825435  \n",
       "1   0.6000  1.235000  \n",
       "0   0.8000  1.049750  \n",
       "5   0.8000  1.049750  \n",
       "19  0.5600  1.300000  \n",
       "17  0.6000  1.300000  \n",
       "6   0.6000  1.300000  \n",
       "22  0.7125  1.215500  \n",
       "2   0.7000  1.235000  \n",
       "11  0.7200  1.215500  \n",
       "7   1.0000  0.949000  \n",
       "16  0.9500  1.049750  \n",
       "23  0.7125  1.300000  \n",
       "3   0.7200  1.300000  \n",
       "9   1.0000  1.029600  \n",
       "12  1.0000  1.049750  \n",
       "20  0.8000  1.300000  \n",
       "18  1.0000  1.300000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max possible score is 2.30.\n",
    "\n",
    "table(pairs).sort_values(by='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work\n",
    "\n",
    "The scoring system seems 'good enough' to me in that it mostly captures 'rhymes' (which I use to mean interesting sonic correspondences) and mostly rejects uninteresting pairs. The ordering of scores can be a bit flaky, so it would be good to improve that at some point. Several reveiwers have expressed concern that ignoring vowel lengths sometimes causes pairs that score too highly. It would be great to reflect spoken vowel length, but it is a little tricky when we have vowels that lengthen to 'make position' (which technical Latin poetry thing)--it is not certain how those vowels were pronounced, all I would be able to say for sure is how the vowels were _scanned_. At that point we would need to sort through the phonological debate between 'Allen style' and 'Calabrese style' pronunciation constructions, which is not something I look forward to with extreme pleasure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silius",
   "language": "python",
   "name": "silius"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
