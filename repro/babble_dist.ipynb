{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T01:40:11.911483Z",
     "iopub.status.busy": "2021-07-22T01:40:11.911131Z",
     "iopub.status.idle": "2021-07-22T01:40:11.922567Z",
     "shell.execute_reply": "2021-07-22T01:40:11.919175Z",
     "shell.execute_reply.started": "2021-07-22T01:40:11.911414Z"
    }
   },
   "source": [
    "# Word Distributions in the Simulated Text\n",
    "\n",
    "As noted in the paper, the rhyme baselines at the various positions match well between the simulated texts and the real texts, but there might be concern that the overall distribution of words that end up being used in the simulation are differently distributed (eg some words might never appear due to the algorithm, affecting the rhyme possibilities). Here we carry out a fairly rough and ready sanity check on the final words of the Aeneid vs the simulated Aeneid-like lines. The final words are chosen because they are the ones most constrained by my fairly simplistic greedy line-building algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:13:02.603854Z",
     "iopub.status.busy": "2021-07-22T02:13:02.603458Z",
     "iopub.status.idle": "2021-07-22T02:13:04.293495Z",
     "shell.execute_reply": "2021-07-22T02:13:04.290973Z",
     "shell.execute_reply.started": "2021-07-22T02:13:02.603784Z"
    }
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from mqdq import rhyme, utils, rhyme_classes, babble\n",
    "\n",
    "import random\n",
    "import string\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:13:04.296463Z",
     "iopub.status.busy": "2021-07-22T02:13:04.296016Z",
     "iopub.status.idle": "2021-07-22T02:13:17.356856Z",
     "shell.execute_reply": "2021-07-22T02:13:17.356095Z",
     "shell.execute_reply.started": "2021-07-22T02:13:04.296383Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the Babbler that will create out simulated lines\n",
    "\n",
    "aen_single_bab = babble.Babbler.from_file('mqdq/VERG-aene.xml', name='Aeneid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:13:17.359028Z",
     "iopub.status.busy": "2021-07-22T02:13:17.358683Z",
     "iopub.status.idle": "2021-07-22T02:13:27.527060Z",
     "shell.execute_reply": "2021-07-22T02:13:27.526227Z",
     "shell.execute_reply.started": "2021-07-22T02:13:17.358893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9840 lines in the Aeneid.\n"
     ]
    }
   ],
   "source": [
    "print(\"%d lines in the Aeneid.\" % len(aen_single_bab._syl_source()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We create 5x more simulated text than real\n",
    "\n",
    "As a natural consequence of random sampling, if we create a simulated text of the same length there will be many words that do not appear. In general for $N$ unique items, a sample with replacement of $n=N$ will hit about two-thirds of the items. To see if the full range of words are able to appear we need to sample more than $N$. The factor of five is arbitrary, but should be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:13:27.528734Z",
     "iopub.status.busy": "2021-07-22T02:13:27.528411Z",
     "iopub.status.idle": "2021-07-22T02:15:22.876896Z",
     "shell.execute_reply": "2021-07-22T02:15:22.876146Z",
     "shell.execute_reply.started": "2021-07-22T02:13:27.528595Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "sim = rhyme.syllabify(aen_single_bab.hexameter(9840*5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:15:22.878215Z",
     "iopub.status.busy": "2021-07-22T02:15:22.877861Z",
     "iopub.status.idle": "2021-07-22T02:15:22.889093Z",
     "shell.execute_reply": "2021-07-22T02:15:22.887300Z",
     "shell.execute_reply.started": "2021-07-22T02:15:22.878051Z"
    }
   },
   "outputs": [],
   "source": [
    "strip_punc = lambda s: s.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:15:22.891674Z",
     "iopub.status.busy": "2021-07-22T02:15:22.891215Z",
     "iopub.status.idle": "2021-07-22T02:15:23.379428Z",
     "shell.execute_reply": "2021-07-22T02:15:23.378710Z",
     "shell.execute_reply.started": "2021-07-22T02:15:22.891603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up Counter objects to get counts by unique word\n",
    "\n",
    "sim_ctr = Counter([strip_punc(x[-1].mqdq.text.lower()) for x in sim])\n",
    "aen_ctr = Counter([strip_punc(x[-1].mqdq.text.lower()) for x in aen_single_bab._syl_source()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *range* of words that appear is more or less the same\n",
    "\n",
    "This shows that any final word in the real Aeneid might be selected as a final word for the simulated text. The is an apparent discrepancy in the numbers here--there are 3636 unique words in the simulated text, but only 3625 that appear in both, ie there are 11 final words in the simulated text that do not appear in the original. This is a feature of the algorithm, which can (very rarely) pick a word from the penultimate position if certain coincidences of elision occur, and isn't something to worry about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:15:23.380767Z",
     "iopub.status.busy": "2021-07-22T02:15:23.380407Z",
     "iopub.status.idle": "2021-07-22T02:15:23.389052Z",
     "shell.execute_reply": "2021-07-22T02:15:23.386821Z",
     "shell.execute_reply.started": "2021-07-22T02:15:23.380599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3640 unique final words in Aeneid, 3636 in simulated text.\n"
     ]
    }
   ],
   "source": [
    "print(\"%d unique final words in Aeneid, %d in simulated text.\" % (len(aen_ctr),len(sim_ctr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:15:23.391427Z",
     "iopub.status.busy": "2021-07-22T02:15:23.391054Z",
     "iopub.status.idle": "2021-07-22T02:15:23.405498Z",
     "shell.execute_reply": "2021-07-22T02:15:23.403709Z",
     "shell.execute_reply.started": "2021-07-22T02:15:23.391360Z"
    }
   },
   "outputs": [],
   "source": [
    "# For each word that appears in both texts, store the difference in counts.\n",
    "# Divide the counts for the simulated text by 5 (obviously)\n",
    "\n",
    "diffs = []\n",
    "for (word, count) in aen_ctr.items():\n",
    "    if sim_ctr[word]:\n",
    "        diffs.append(count - (sim_ctr[word]/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:15:23.407824Z",
     "iopub.status.busy": "2021-07-22T02:15:23.407259Z",
     "iopub.status.idle": "2021-07-22T02:15:23.439286Z",
     "shell.execute_reply": "2021-07-22T02:15:23.428837Z",
     "shell.execute_reply.started": "2021-07-22T02:15:23.407744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3625 unique words appear in both (99.59% of Aeneid final words are represented)\n"
     ]
    }
   ],
   "source": [
    "print(\"%d unique words appear in both (%.2f%% of Aeneid final words are represented)\" %(len(diffs), len(diffs)/len(aen_ctr)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *distribution* of words is not significantly different\n",
    "\n",
    "We use the Wilcoxon signed rank test (more information and references [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html#scipy.stats.wilcoxon))\n",
    "\n",
    "<blockquote>\n",
    "The Wilcoxon signed-rank test tests the null hypothesis that two related paired samples come from the same distribution. In particular, it tests whether the distribution of the differences x - y is symmetric about zero. It is a non-parametric version of the paired T-test.\n",
    "</blockquote>\n",
    "\n",
    "In the tests below we test with and without Pratt's adjustment for zero differences (which is more conservative). In both cases the p-value is not significant, so we retain $H_0$, which is that the two samples are drawn from the same distribution. In other words the frequency with which the words appear in the simulated text is a fairly good match to the real text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:15:23.443099Z",
     "iopub.status.busy": "2021-07-22T02:15:23.442710Z",
     "iopub.status.idle": "2021-07-22T02:15:23.471272Z",
     "shell.execute_reply": "2021-07-22T02:15:23.462622Z",
     "shell.execute_reply.started": "2021-07-22T02:15:23.443034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=2394540.5, pvalue=0.34391369159103546)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.wilcoxon(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:15:23.473324Z",
     "iopub.status.busy": "2021-07-22T02:15:23.472963Z",
     "iopub.status.idle": "2021-07-22T02:15:23.502029Z",
     "shell.execute_reply": "2021-07-22T02:15:23.498120Z",
     "shell.execute_reply.started": "2021-07-22T02:15:23.473270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=3141540.5, pvalue=0.1925915136016152)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.stats.wilcoxon(diffs, zero_method='pratt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The most common words are a good match\n",
    "\n",
    "Finally, here are the 15 most common words from both sets. The match seems fairly good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:27:02.237152Z",
     "iopub.status.busy": "2021-07-22T02:27:02.236720Z",
     "iopub.status.idle": "2021-07-22T02:27:02.245740Z",
     "shell.execute_reply": "2021-07-22T02:27:02.244655Z",
     "shell.execute_reply.started": "2021-07-22T02:27:02.236978Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('armis', 100),\n",
       " ('auras', 60),\n",
       " ('urbem', 49),\n",
       " ('alto', 42),\n",
       " ('omnis', 41),\n",
       " ('arma', 37),\n",
       " ('circum', 35),\n",
       " ('est', 34),\n",
       " ('oris', 30),\n",
       " ('undis', 30),\n",
       " ('fatur', 29),\n",
       " ('altis', 27),\n",
       " ('hostis', 27),\n",
       " ('ferro', 26),\n",
       " ('bello', 26)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aen_ctr.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-22T02:27:06.689811Z",
     "iopub.status.busy": "2021-07-22T02:27:06.688373Z",
     "iopub.status.idle": "2021-07-22T02:27:06.701632Z",
     "shell.execute_reply": "2021-07-22T02:27:06.700395Z",
     "shell.execute_reply.started": "2021-07-22T02:27:06.689714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('armis', 494),\n",
       " ('auras', 303),\n",
       " ('urbem', 229),\n",
       " ('alto', 211),\n",
       " ('omnis', 204),\n",
       " ('circum', 185),\n",
       " ('arma', 172),\n",
       " ('oris', 168),\n",
       " ('ferro', 146),\n",
       " ('apollo', 145),\n",
       " ('hostis', 145),\n",
       " ('bello', 143),\n",
       " ('fatur', 136),\n",
       " ('altis', 132),\n",
       " ('undis', 131)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_ctr.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Conclusions\n",
    "\n",
    "This seems to indicate that the lexical palette is a good statistical match for the real text (good enough to fool a computer, at least). There are other meta-lexical features (double-disyllables etc) that would be noticed as non-Vergilian by a human, but the algorithm is good enough for its purpose. \n",
    "\n",
    "Any word in a given position might appear in the simulated text, and will appear with roughly the same frequency as in the real text (rare words remain rare, common words remain common)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silius",
   "language": "python",
   "name": "silius"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
